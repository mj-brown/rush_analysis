{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3f3b271",
   "metadata": {},
   "source": [
    "# Final Project: RUSH Business Case Analysis\n",
    "Class: GEN BUS 885\\\n",
    "Author: Matthew Brown\\\n",
    "Date: 07/29/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e59e756",
   "metadata": {},
   "source": [
    "## Business Scenario\n",
    "You work as a sales analyst for RUSH, a globally renowned sportswear and footwear brand known for its innovative designs and performance-oriented products. The company stores its raw sales data as a collection of three tables:\n",
    "+ TABLE_PRODUCTS\n",
    "+ TABLE_RETAILER\n",
    "+ TABLE_SALES\n",
    "\n",
    "The data includes the number of units sold, the total sales revenue, the location of the sales, the type of product sold, as well as other relevant information. (For data field definitions and explanations, see the data dictionary.) The data is \"raw,\" meaning it has not been cleaned and probably contains errors that need to be addressed.\n",
    "\n",
    "The VP of US Sales has tasked you with analyzing sales data for trends and insights that will help company leadership understand the market and identify opportunities for growth. For example, you may want to look for trends or insights in seasonality, retailers, locations, or sales methods. Take initiative to apply your creativity and curiosity to this data.\n",
    "\n",
    "In addition, she has asked you to answer the following business questions:\n",
    "1. What product category (product) had the highest sales (in dollars) in 2021? How much did it sell?\n",
    "2. What state had the highest sales (in dollars) of women's products in 2021? How much was it?\n",
    "3. What state had the highest sales (in dollars) of men's products in 2021? How much was it?\n",
    "4. What retailer purchased the most units in 2021? In 2020?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f350602d",
   "metadata": {},
   "source": [
    "## Install and Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08435da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\brown\\appdata\\roaming\\python\\python313\\site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\brown\\appdata\\roaming\\python\\python313\\site-packages (2.3.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\brown\\appdata\\roaming\\python\\python313\\site-packages (3.10.5)\n",
      "Requirement already satisfied: seaborn in c:\\users\\brown\\appdata\\roaming\\python\\python313\\site-packages (0.13.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\brown\\appdata\\roaming\\python\\python313\\site-packages (1.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\brown\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\brown\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\brown\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\brown\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\brown\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\brown\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\brown\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\brown\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\brown\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\brown\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\brown\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\brown\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\brown\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\brown\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages\n",
    "%pip install pandas numpy matplotlib seaborn scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8170800d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m#import pprint\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m#import matplotlib.ticker as ticker\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\seaborn\\__init__.py:5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpalettes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrelational\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mregression\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcategorical\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\seaborn\\relational.py:21\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     14\u001b[39m     adjust_legend_subtitles,\n\u001b[32m     15\u001b[39m     _default_color,\n\u001b[32m   (...)\u001b[39m\u001b[32m     18\u001b[39m     _scatter_legend_artist,\n\u001b[32m     19\u001b[39m )\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_compat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m groupby_apply_include_groups\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_statistics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EstimateAggregator, WeightedAggregator\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01maxisgrid\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FacetGrid, _facet_docs\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_docstrings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DocstringComponents, _core_docs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\seaborn\\_statistics.py:32\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstats\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gaussian_kde\n\u001b[32m     33\u001b[39m     _no_scipy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\scipy\\stats\\__init__.py:655\u001b[39m\n\u001b[32m    651\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_distribution_infrastructure\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    652\u001b[39m     make_distribution, Mixture, order_statistic, truncate, exp, log, \u001b[38;5;28mabs\u001b[39m\n\u001b[32m    653\u001b[39m )\n\u001b[32m    654\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_new_distributions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Normal, Uniform, Binomial\n\u001b[32m--> \u001b[39m\u001b[32m655\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_mgc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m multiscale_graphcorr\n\u001b[32m    656\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_correlation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m chatterjeexi\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_quantile\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m quantile\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\scipy\\stats\\_mgc.py:7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_lib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_bunch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _make_tuple_bunch\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mspatial\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistance\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cdist\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mndimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _measurements\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_stats\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _local_correlations  \u001b[38;5;66;03m# type: ignore[import-not-found]\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m distributions\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\scipy\\ndimage\\__init__.py:157\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03m=========================================================\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mMultidimensional image processing (:mod:`scipy.ndimage`)\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    120\u001b[39m \n\u001b[32m    121\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# Copyright (C) 2003-2005 Peter J. Verveer\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    125\u001b[39m \u001b[38;5;66;03m# Redistribution and use in source and binary forms, with or without\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    154\u001b[39m \n\u001b[32m    155\u001b[39m \u001b[38;5;66;03m# mypy: ignore-errors\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_support_alternative_backends\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m    159\u001b[39m \u001b[38;5;66;03m# adjust __all__ and do not leak implementation details\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _support_alternative_backends\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\scipy\\ndimage\\_support_alternative_backends.py:7\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_lib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_array_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      3\u001b[39m     is_cupy, is_jax, scipy_namespace_for, SCIPY_ARRAY_API\n\u001b[32m      4\u001b[39m )\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_ndimage_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *   \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _ndimage_api\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _delegators\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\scipy\\ndimage\\_ndimage_api.py:12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_fourier\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *   \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_interpolation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *   \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_measurements\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *   \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_morphology\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *   \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# '@' due to pytest bug, scipy/scipy#22236\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\scipy\\ndimage\\_measurements.py:33\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _ni_support\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _ni_label\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _nd_image\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _morphology\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:645\u001b[39m, in \u001b[36mparent\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Import ncessary packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#import pprint\n",
    "#import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071f6ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untruncate output\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302a3b65",
   "metadata": {},
   "source": [
    "## Load Data and Create DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c1267b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the product data from TABLE_PRODUCTS_885.csv into a Dataframe called products_df.\n",
    "products_df = pd.read_csv('data/TABLE_PRODUCTS_885.csv', sep = '|')\n",
    "\n",
    "# View the first few rows of products_df\n",
    "products_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e459ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the retailer data from TABLE_RETAILER_885.csv into a Dataframe called retailers_df.\n",
    "retailers_df = pd.read_csv('data/TABLE_RETAILER_885.csv')\n",
    "\n",
    "# View the first few rows of retailers_df\n",
    "retailers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7b97a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sales data from TABLE_SALES_885.csv into a Dataframe called sales_df.\n",
    "sales_df = pd.read_csv('data/TABLE_SALES_885.csv')\n",
    "\n",
    "# View the first few rows of sales_df\n",
    "sales_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909bca83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine sales_df and products_df on the PRODUCT_ID column\n",
    "sales_products_df = sales_df.merge(products_df, how = 'left', on = 'PRODUCT_ID')\n",
    "\n",
    "# Combine the sales_products_df and retailers_df on the RETAILER_ID column\n",
    "rush_sales_df = sales_products_df.merge(retailers_df, how = 'left', on = 'RETAILER_ID')\n",
    "\n",
    "# View the first few rows of rush_sales_df\n",
    "rush_sales_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b98d0d7",
   "metadata": {},
   "source": [
    "## Inspect the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fabcb54",
   "metadata": {},
   "source": [
    "### Inspect the DataFrame Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27cbd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the shape of rush_sales_df\n",
    "rush_sales_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1b3acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the info of rush_sales_df\n",
    "rush_sales_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6fcff5",
   "metadata": {},
   "source": [
    "### Characteristics Check Results\n",
    "+ The DataFrame has 16 columns with 10,271 rows.\n",
    "+ No unwanted observations.\n",
    "+ No unwanted features.\n",
    "+ The ``INVOICE_DATE`` column is an object, we want to turn that into Date datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cd05b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the INVOICE_DATE column to datetime format\n",
    "rush_sales_df['INVOICE_DATE'] = pd.to_datetime(rush_sales_df['INVOICE_DATE'])\n",
    "\n",
    "# View the information for the rush_sales_df\n",
    "rush_sales_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da931d6",
   "metadata": {},
   "source": [
    "### Identify any Unwanted Observations or Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94330178",
   "metadata": {},
   "source": [
    "+ There are no Unwanted Observations or Features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade3f881",
   "metadata": {},
   "source": [
    "### Inspect for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac3e24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traditional Null Values Check\n",
    "rush_sales_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f5f2a2",
   "metadata": {},
   "source": [
    "There are traditional null values in the following columns:\n",
    "+ PRICE_PER_PRODUCT: 2\n",
    "+ RETAILER: 1\n",
    "+ REGION: 1\n",
    "+ STATE: 1\n",
    "+ CITY: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19909b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-Traditional Categorical Null Values Check\n",
    "# Identify by viewing unique values in each categorical column\n",
    "\n",
    "# List of categorical columns to inspect by type\n",
    "cat_columns = list(rush_sales_df.select_dtypes(include = 'object').columns)\n",
    "\n",
    "# View unique values in each categorical column\n",
    "for col in cat_columns:\n",
    "    unique_values = rush_sales_df[col].dropna().astype(str).unique().tolist()\n",
    "    unique_values.sort()\n",
    "    print(f\"Unique values in column '{col}':\")\n",
    "    pprint.pprint(unique_values)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56b74db",
   "metadata": {},
   "source": [
    "Some unique null values to address later on are as follows:\n",
    "+ RETAILER_ID: 999999999\n",
    "+ UNITS_SOLD: *** and 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1543caad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-Traditional Numerical Null Values Check\n",
    "rush_sales_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79566890",
   "metadata": {},
   "source": [
    "There is one column that has a non-traditional numerical null value.\n",
    "\n",
    "+ PRICE_PER_UNIT has at least one value of 99999."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674da418",
   "metadata": {},
   "source": [
    "### Inspect for Duplicate Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5ab9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect for Duplicate values\n",
    "duplicate_rows = rush_sales_df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicate_rows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81765232",
   "metadata": {},
   "source": [
    "There are no duplicate rows in the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a85de5",
   "metadata": {},
   "source": [
    "### Inspect for Erroneous Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a393c284",
   "metadata": {},
   "source": [
    "There was one previously identified erroneous value in the dataframe.\n",
    "+ SALES_METHOD: Ootlet instead of Outlet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a18772d",
   "metadata": {},
   "source": [
    "### Inspect for Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60d3a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the IQR method to identify outliers\n",
    "# Write a function to calculate IQR and print rows with values that fall outside the IQR range\n",
    "def detect_outliers_iqr(df, column):\n",
    "    # Define Q1\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    # Define Q3\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    # Calculate IQR and define bounds\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    # Identify outliers\n",
    "    outliers = (df[column] < lower_bound) | (df[column] > upper_bound)\n",
    "    # Count the number of True values (Outliers)\n",
    "    return outliers.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cf1208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the numeric columns and identify outliers\n",
    "for col in rush_sales_df.select_dtypes(include = 'number').columns:\n",
    "    print(f\"Number of outliers in column '{col}': {detect_outliers_iqr(rush_sales_df, col)}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bacf0a7",
   "metadata": {},
   "source": [
    "There are 3 columns that have possible outliers:\n",
    "+ YEAR\n",
    "+ PRICE_PER_UNIT\n",
    "+ OPERATING_MARGIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013778de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate outliers in year.\n",
    "year_outliers = rush_sales_df[(rush_sales_df['YEAR'] > 2021) | (rush_sales_df['YEAR'] < 2020)]\n",
    "\n",
    "print(year_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45f05ef",
   "metadata": {},
   "source": [
    "There are no outliers in the year column, all years are 2020 or 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf37163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate outliers in PRICE_PER_UNIT.\n",
    "Q1 = rush_sales_df['PRICE_PER_UNIT'].quantile(0.25)\n",
    "Q3 = rush_sales_df['PRICE_PER_UNIT'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "outliers = rush_sales_df[(rush_sales_df['PRICE_PER_UNIT'] < lower_bound) | \n",
    "                         (rush_sales_df['PRICE_PER_UNIT'] > upper_bound)]\n",
    "\n",
    "outliers.sort_values(by = ['PRICE_PER_UNIT', 'REGION', 'RETAILER_ID', 'PRODUCT_ID'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff93c63c",
   "metadata": {},
   "source": [
    "The PRICE_PER_PRODUCT outliers appear to not necessarily be outliers.  While they are the same product_name or category, they are different product id's and in different regions.  Some of the regions have a much higher cost of living in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d11772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate outliers in OPERATING_MARGIN.\n",
    "Q1 = rush_sales_df['OPERATING_MARGIN'].quantile(0.25)\n",
    "Q3 = rush_sales_df['OPERATING_MARGIN'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "margin_outliers = rush_sales_df[\n",
    "    (rush_sales_df['OPERATING_MARGIN'] < lower_bound) | \n",
    "    (rush_sales_df['OPERATING_MARGIN'] > upper_bound)\n",
    "]\n",
    "\n",
    "margin_outliers.sort_values(by = ['OPERATING_MARGIN', 'REGION', 'RETAILER_ID', 'PRODUCT_ID'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e03d29e",
   "metadata": {},
   "source": [
    "Not necessarily outliers that need to be fixed.  These plaices may all have operating margin's that are differnet since it appears that they are in different locations and regions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153615ec",
   "metadata": {},
   "source": [
    "## Clean the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d7aae3",
   "metadata": {},
   "source": [
    "### Address Unwanted Observations or Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3819f3b2",
   "metadata": {},
   "source": [
    "There are no Unwanted Observations or Features to address."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce8255c",
   "metadata": {},
   "source": [
    "### Address any Erroneous Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34a9291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the erroneous value for SALES_METHOD of Ootlet with Outlet\n",
    "rush_sales_df.loc[rush_sales_df['SALES_METHOD'] == 'Ootlet', 'SALES_METHOD'] = 'Outlet'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0570934",
   "metadata": {},
   "source": [
    "### Address any Duplicate Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7599e35",
   "metadata": {},
   "source": [
    "There are no duplicate rows to address."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64d3969",
   "metadata": {},
   "source": [
    "### Address any Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4bdf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check row with null values in RETAILER column\n",
    "rush_sales_df[rush_sales_df['RETAILER'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f2ab4f",
   "metadata": {},
   "source": [
    "Based on there being no desernable information to identify who the retailer is or where the retailer is located, and the fact this row is a singular row, I am going to exclude it from analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdac5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete row from rush dataframe where RETAILER is null\n",
    "rush_sales_df = rush_sales_df.drop(rush_sales_df[rush_sales_df['RETAILER'].isnull()].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01edd087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check row where PRICE_PER_UNIT is null\n",
    "rush_sales_df[rush_sales_df['PRICE_PER_UNIT'].isnull()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23aa5343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the mean PRICE_PER_UNIT for products that have a PRODUCT_ID of 20, OPERATING_MARGIN of 0.35, SALES_METHOD of In-store, REGION of Northeast, STATE of Vermont, and CITY of Burlington\n",
    "rush_sales_df[rush_sales_df['PRODUCT_ID'] == 20].groupby(['OPERATING_MARGIN', 'SALES_METHOD', 'REGION', 'STATE', 'CITY'])['PRICE_PER_UNIT'].median()\n",
    "\n",
    "# Filter the results by OPERATING_MARGIN of 0.35, SALES_METHOD of In-store, REGION of Northeast, STATE of Vermont, and CITY of Burlington\n",
    "rush_sales_df[rush_sales_df['OPERATING_MARGIN'] == 0.35].groupby(['SALES_METHOD', 'REGION', 'STATE', 'CITY'])['PRICE_PER_UNIT'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59614350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the same process for products that have a PRODUCT_ID of 20, OPERATING_MARGIN of 0.50, SALES_METHOD of In-store, REGION of Northeast, STATE of Vermont, and CITY of Burlington\n",
    "rush_sales_df[rush_sales_df['PRODUCT_ID'] == 20].groupby(['OPERATING_MARGIN', 'SALES_METHOD', 'REGION', 'STATE', 'CITY'])['PRICE_PER_UNIT'].median()\n",
    "rush_sales_df[rush_sales_df['OPERATING_MARGIN'] == 0.50].groupby(['SALES_METHOD', 'REGION', 'STATE', 'CITY'])['PRICE_PER_UNIT'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0547b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the null values for the PRICE_PER_UNIT when OPERATING_MARGIN is 0.35 with 60.0.\n",
    "rush_sales_df.loc[(rush_sales_df['PRICE_PER_UNIT'].isnull()) & (rush_sales_df['OPERATING_MARGIN'] == 0.35), 'PRICE_PER_UNIT'] = 60.0\n",
    "\n",
    "# Replace the null values for the PRICE_PER_UNIT when OPERATING_MARGIN is 0.50 with 65.0.\n",
    "rush_sales_df.loc[(rush_sales_df['PRICE_PER_UNIT'].isnull()) & (rush_sales_df['OPERATING_MARGIN'] == 0.50), 'PRICE_PER_UNIT'] = 65.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7390f335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out PRICE_PER_UNIT when value is 99999.\n",
    "rush_sales_df[rush_sales_df['PRICE_PER_UNIT'] == 99999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7869886a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the same process for products that have a PRODUCT_ID of 20, OPERATING_MARGIN of 0.4, SALES_METHOD of Online, RETAILER of Foot Locker, REGION of Northeast, STATE of New Hampshire, and CITY of Manchester\n",
    "rush_sales_df[rush_sales_df['PRODUCT_ID'] == 20].groupby(['OPERATING_MARGIN', 'SALES_METHOD', 'REGION', 'STATE', 'CITY'])['PRICE_PER_UNIT'].median()\n",
    "rush_sales_df[rush_sales_df['OPERATING_MARGIN'] == 0.40].groupby(['SALES_METHOD', 'REGION', 'STATE', 'CITY'])['PRICE_PER_UNIT'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e19ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the 99999 in PRICE_PER_UNIT with 45.0.\n",
    "rush_sales_df.loc[rush_sales_df['PRICE_PER_UNIT'] == 99999, 'PRICE_PER_UNIT'] = 45.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2519f60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out rows where UNITS_SOLD are ***.\n",
    "rush_sales_df[rush_sales_df['UNITS_SOLD'] == '***']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f4adf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine like rows.\n",
    "rush_sales_df[(rush_sales_df['OPERATING_MARGIN'] == 0.45) & (rush_sales_df['YEAR'] == 2021) & (rush_sales_df['SALES_METHOD'] == 'Online') & (rush_sales_df['REGION'] == 'South') & (rush_sales_df['RETAILER'] == 'Sports Direct') & (rush_sales_df['STATE'] == 'Alabama') & (rush_sales_df['PRODUCT_ID'] == 20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f543fc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the *** in UNITS_SOLD with 154 for row 1021.\n",
    "rush_sales_df.loc[1021, 'UNITS_SOLD'] = 154"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e92ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out rows where UNITS_SOLD are ***.\n",
    "rush_sales_df[rush_sales_df['UNITS_SOLD'] == '***']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9f45a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine like rows.\n",
    "rush_sales_df[(rush_sales_df['OPERATING_MARGIN'] == 0.46) & (rush_sales_df['YEAR'] == 2021) & (rush_sales_df['SALES_METHOD'] == 'Outlet') & (rush_sales_df['REGION'] == 'Midwest') & (rush_sales_df['RETAILER'] == 'West Gear') & (rush_sales_df['STATE'] == 'Iowa') & (rush_sales_df['PRODUCT_ID'] == 20)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a991beb",
   "metadata": {},
   "source": [
    "Since this is another singular row, I am going to exclude it from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7e1459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the record with UNITS_SOLD of ***.\n",
    "rush_sales_df = rush_sales_df.drop(rush_sales_df[rush_sales_df['UNITS_SOLD'] == '***'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ff1cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert UNITS_SOLD TO INT.\n",
    "rush_sales_df['UNITS_SOLD'] = rush_sales_df['UNITS_SOLD'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534a4c91",
   "metadata": {},
   "source": [
    "### Address any Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604f0ce9",
   "metadata": {},
   "source": [
    "The outliers identified above will be investigated further in the ``Determine Any Additional Trends or Insights`` section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916907db",
   "metadata": {},
   "source": [
    "## Answer the Business Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447cf610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refresh list of columns with info.\n",
    "rush_sales_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7ca1ee",
   "metadata": {},
   "source": [
    "### 1. What product category (product) had the highest sales (in dollars) in 2021? How much did it sell?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14e7801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the results to only be results from the year 2021 and save to a df called rush_sales_2021.\n",
    "rush_sales_2021 = rush_sales_df[rush_sales_df['YEAR'] == 2021].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1805c297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column to rush_sales_2021 caled sales_total that is the product of PRICE_PER_UNIT and UNITS_SOLD.\n",
    "rush_sales_2021.loc[:, 'SALES_TOTAL'] = rush_sales_2021['PRICE_PER_UNIT'] * rush_sales_2021['UNITS_SOLD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1438ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by PRODUCT_NAME and sum the SALES_TOTAL column, and return the top 5 highest resullts.\n",
    "rush_sales_2021.groupby('PRODUCT_NAME')['SALES_TOTAL'].sum().sort_values(ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754279e6",
   "metadata": {},
   "source": [
    "+ The product with the highest total sales (in dollars) in 2021 is ``Men's Street Footwear``.\n",
    "+ The total amount sold was ``$23,288,610.00``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82aabeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group and sum the sales by product\n",
    "top_products = (\n",
    "    rush_sales_2021\n",
    "    .groupby('PRODUCT_NAME', as_index=False)['SALES_TOTAL']\n",
    "    .sum()\n",
    "    .sort_values(by='SALES_TOTAL', ascending=False)\n",
    "    .head(3)\n",
    ")\n",
    "\n",
    "# Filter original dataset for only the top 3 products\n",
    "filtered_data = rush_sales_2021[rush_sales_2021['PRODUCT_NAME'].isin(top_products['PRODUCT_NAME'])]\n",
    "\n",
    "# Plot the bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(\n",
    "    data=filtered_data,\n",
    "    x='PRODUCT_NAME',\n",
    "    y='SALES_TOTAL',\n",
    "    estimator='sum',\n",
    "    errorbar=None\n",
    ")\n",
    "\n",
    "# Format the plot\n",
    "plt.title('Top 3 Products by Total Sales')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Total Sales (in $10M)')\n",
    "plt.xlabel('Product Name')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cb402a",
   "metadata": {},
   "source": [
    "### 2. What state had the highest sales (in dollars) of women's products in 2021? How much was it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3263626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GENDER column to identify if the product is for Men or Women (0 = Men, 1 = Women).\n",
    "rush_sales_2021.loc[rush_sales_2021['PRODUCT_NAME'].str.contains(\"Men's\", case=False, na=False), 'GENDER'] = 0\n",
    "rush_sales_2021.loc[rush_sales_2021['PRODUCT_NAME'].str.contains(\"Women's\", case=False, na=False), 'GENDER'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12b1f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for rows where GENDER == 1 (Women's).\n",
    "womens_products = rush_sales_2021[rush_sales_2021['GENDER'] == 1]\n",
    "\n",
    "# Group by STATE and sum the SALES_TOTAL column, and return the top results.\n",
    "womens_products.groupby('STATE')['SALES_TOTAL'].sum().sort_values(ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8181b3cf",
   "metadata": {},
   "source": [
    "+ The state with the highest sales (in dollars) for women's products in 2021 was ``Maine``.\n",
    "+ The amount of sales was ``$2,176,301.00``."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524d509a",
   "metadata": {},
   "source": [
    "### 3. What state had the highest sales (in dollars) of men's products in 2021? How much was it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7c2053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for rows where GENDER == 0 (Men's).\n",
    "mens_products = rush_sales_2021[rush_sales_2021['GENDER'] == 0]\n",
    "\n",
    "# Group by STATE and sum the SALES_TOTAL column, and return the results.\n",
    "mens_products.groupby('STATE')['SALES_TOTAL'].sum().sort_values(ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebafb13",
   "metadata": {},
   "source": [
    "+ The state with the highest sales (in dollars) for men's products in 2021 was ``Delaware``.\n",
    "+ The amount of sales was ``$2,334,300.00``."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb95ace",
   "metadata": {},
   "source": [
    "### 4. What retailer purchased the most units in 2021? In 2020?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6849b9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the results to only be results from the year 2020 and save to a df called rush_sales_2020.\n",
    "rush_sales_2020 = rush_sales_df[rush_sales_df['YEAR'] == 2020].copy()\n",
    "\n",
    "# Add a column to rush_sales_2020 caled sales_total that is the product of PRICE_PER_UNIT and UNITS_SOLD.\n",
    "rush_sales_2020.loc[:, 'SALES_TOTAL'] = rush_sales_2020['PRICE_PER_UNIT'] * rush_sales_2020['UNITS_SOLD']\n",
    "\n",
    "# Create a GENDER column to identify if the product is for Men or Women (0 = Men, 1 = Women).\n",
    "rush_sales_2020.loc[rush_sales_2020['PRODUCT_NAME'].str.contains(\"Men's\", case=False, na=False), 'GENDER'] = 0\n",
    "rush_sales_2020.loc[rush_sales_2020['PRODUCT_NAME'].str.contains(\"Women's\", case=False, na=False), 'GENDER'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536b4a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the rush_sales_2021 df by RETAILER and sum UNITS_SOLD, and then return the results.\n",
    "rush_sales_2021.groupby('RETAILER')['UNITS_SOLD'].sum().sort_values(ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4048ff86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the rush_sales_2020 df by RETAILER and sum UNITS_SOLD, and then return the Results.\n",
    "rush_sales_2020.groupby('RETAILER')['UNITS_SOLD'].sum().sort_values(ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58785ffe",
   "metadata": {},
   "source": [
    "+ The retailer who purchased the most units in 2021 was ``Foot Locker``.\n",
    "+ The retailer who purchased the most units in 2020 was ``Amazon``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe79227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fcbd81b",
   "metadata": {},
   "source": [
    "## Determine Any Additional Trends or Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6874241a",
   "metadata": {},
   "source": [
    "### What product had the lowest sales in 2021? How much sold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cb446f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which product had the lowest sales in 2021.\n",
    "rush_sales_2021.groupby('PRODUCT_NAME')['SALES_TOTAL'].sum().sort_values(ascending = True).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7bacbc",
   "metadata": {},
   "source": [
    "### What state had the lowest sales of women's products in 2021?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68d6a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deterimne which state had the lowest sales of women's products in 2021?\n",
    "womens_products.groupby('STATE')['SALES_TOTAL'].sum().sort_values(ascending = True).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a9abf8",
   "metadata": {},
   "source": [
    "### What state had the lowest sales of men's products in 2021?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339ea27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which state had the lowest sales of men's products in 2021.\n",
    "mens_products.groupby('STATE')['SALES_TOTAL'].sum().sort_values(ascending = True).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2b5b73",
   "metadata": {},
   "source": [
    "### What region had the highest sales in 2021? The lowest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535d7609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which region had the highest sales in 2021.\n",
    "rush_sales_2021.groupby('REGION')['SALES_TOTAL'].sum().sort_values(ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95046914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which region had the lowest sales in 2021.\n",
    "rush_sales_2021.groupby('REGION')['SALES_TOTAL'].sum().sort_values(ascending = True).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9784cb15",
   "metadata": {},
   "source": [
    "### What retailer purchased the least units in 2021? 2020?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc3027b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which retailer purchased the least units in 2021.\n",
    "rush_sales_2021.groupby('RETAILER')['UNITS_SOLD'].sum().sort_values(ascending = True).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692d4d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which retailer purchased the least units in 2020.\n",
    "rush_sales_2020.groupby('RETAILER')['UNITS_SOLD'].sum().sort_values(ascending = True).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d8f028",
   "metadata": {},
   "source": [
    "### What product had the least units sold in 2021? 2020?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6517731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which product had the least units sold in 2021.\n",
    "rush_sales_2021.groupby('PRODUCT_NAME')['UNITS_SOLD'].sum().sort_values(ascending = True).head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b148f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which product had the least units sold in 2020.\n",
    "rush_sales_2020.groupby('PRODUCT_NAME')['UNITS_SOLD'].sum().sort_values(ascending = True).head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb13a9cf",
   "metadata": {},
   "source": [
    "### What retailer, including region, state, city had the highest operating marign? The lowest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9ab19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the retailer with the highest operting margin.  Group by region, state, and city.\n",
    "rush_sales_2021.groupby(['RETAILER', 'REGION', 'STATE', 'CITY'])['OPERATING_MARGIN'].sum().sort_values(ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bee3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the retailer with the lowest operting margin.  Group by region, state, and city.\n",
    "rush_sales_2021.groupby(['RETAILER', 'REGION', 'STATE', 'CITY'])['OPERATING_MARGIN'].sum().sort_values(ascending = True).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1180392a",
   "metadata": {},
   "source": [
    "### Using a bar chart show the relationship between region and product type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d279a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a grouped bar chart using seaborn to show the total units sold by product and region.\n",
    "plt.figure(figsize = (14, 7))\n",
    "sns.barplot(\n",
    "    data = rush_sales_df,\n",
    "    x = 'PRODUCT_NAME',\n",
    "    y = 'UNITS_SOLD',\n",
    "    hue = 'REGION',\n",
    "    estimator = 'sum',\n",
    "    errorbar = None\n",
    ")\n",
    "\n",
    "# Format the plot\n",
    "plt.title('Units Sold by Product and Region')\n",
    "plt.xticks(rotation = 45)\n",
    "plt.ylabel('Units Sold')\n",
    "plt.xlabel('Product Name')\n",
    "\n",
    "# Move legend to top, in a horizontal row\n",
    "plt.legend(\n",
    "    title = 'Region',\n",
    "    loc = 'upper right',\n",
    "    ncol = 5,\n",
    "    frameon = False\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f1d1df",
   "metadata": {},
   "source": [
    "### Using a bar chart show the relationship between product type and retailer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8ae52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a grouped bar chart using seaborn to show the total units sold by product and retailer.\n",
    "plt.figure(figsize = (14, 7))\n",
    "sns.barplot(\n",
    "    data = rush_sales_df,\n",
    "    x = 'PRODUCT_NAME',\n",
    "    y = 'UNITS_SOLD',\n",
    "    hue = 'RETAILER',\n",
    "    estimator = 'sum',\n",
    "    errorbar = None\n",
    ")\n",
    "\n",
    "# Format the plot\n",
    "plt.title('Units Sold by Product and Retailer')\n",
    "plt.xticks(rotation = 45)\n",
    "plt.ylabel('Units Sold')\n",
    "plt.xlabel('Product Name')\n",
    "\n",
    "# Move legend to top, in a horizontal row\n",
    "plt.legend(\n",
    "    title = 'Retailer',\n",
    "    loc = 'upper right',\n",
    "    ncol = 5,\n",
    "    frameon = False\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dbfadd",
   "metadata": {},
   "source": [
    "### Create two line charts showing the sales for each retailer for 2021 and 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f9f575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the total sales by retailer and month for 2021.\n",
    "sales_trend_2021 = rush_sales_2021.groupby(['RETAILER', 'MONTH'])['UNITS_SOLD'].sum().sort_values(ascending = False).reset_index()\n",
    "\n",
    "# Pviot the data to have months as index and retialers as columns\n",
    "trend_pivot_2021 = sales_trend_2021.pivot(index = 'MONTH', columns = 'RETAILER', values = 'UNITS_SOLD')\n",
    "\n",
    "# Sort by month\n",
    "trend_pivot_2021.sort_index()\n",
    "\n",
    "# Plot the trends\n",
    "plt.figure()\n",
    "for retailer in trend_pivot_2021.columns:\n",
    "  plt.plot(trend_pivot_2021.index, trend_pivot_2021[retailer], label = retailer)\n",
    "\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Units Sold')\n",
    "plt.title('2021 Units Sold by Retailer and Month')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc51d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the total sales by retailer and month for 2020.\n",
    "sales_trend_2020 = rush_sales_2020.groupby(['RETAILER', 'MONTH'])['UNITS_SOLD'].sum().sort_values(ascending = False).reset_index()\n",
    "\n",
    "# Pviot the data to have months as index and retialers as columns\n",
    "trend_pivot_2020 = sales_trend_2020.pivot(index = 'MONTH', columns = 'RETAILER', values = 'UNITS_SOLD')\n",
    "\n",
    "# Sort by month\n",
    "trend_pivot_2020.sort_index()\n",
    "\n",
    "# Plot the trends\n",
    "plt.figure()\n",
    "for retailer in trend_pivot_2020.columns:\n",
    "  plt.plot(trend_pivot_2020.index, trend_pivot_2020[retailer], label = retailer)\n",
    "\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Units Sold')\n",
    "plt.title('2020 Units Sold by Retailer and Month')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056aceae",
   "metadata": {},
   "source": [
    "### Create a box plot to show the relationship between price_per_unit and region for the produt types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1408ca99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a grouped boxplot using seaborn to show the price per unit by region and product.\n",
    "plt.figure(figsize = (10, 7))\n",
    "\n",
    "sns.boxplot(\n",
    "    data = rush_sales_df,\n",
    "    x = 'REGION',\n",
    "    y = 'PRICE_PER_UNIT',\n",
    "    hue = 'PRODUCT_NAME'\n",
    ")\n",
    "\n",
    "plt.title('Price per Unit by Region and Product')\n",
    "plt.xlabel('Region')\n",
    "plt.ylabel('Price per Unit')\n",
    "plt.xticks(rotation = 45)\n",
    "plt.legend(title = 'Product Name', bbox_to_anchor = (1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6909f4e6",
   "metadata": {},
   "source": [
    "### Create a bar graph showing the sales volume for each of the product types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08df7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add total_sales to rush_sales_df.\n",
    "rush_sales_with_total = rush_sales_df.copy()\n",
    "\n",
    "rush_sales_with_total['TOTAL_SALES'] = rush_sales_with_total['PRICE_PER_UNIT'] * rush_sales_with_total['UNITS_SOLD']\n",
    "\n",
    "# Group by PRODUCT_NAME and YEAR, summing SALES_TOTAL\n",
    "sales_summary = rush_sales_with_total.groupby(['PRODUCT_NAME', 'YEAR'])['TOTAL_SALES'].sum().reset_index()\n",
    "\n",
    "# Pivot so each YEAR is a separate column\n",
    "sales_pivot = sales_summary.pivot(index = 'PRODUCT_NAME', columns = 'YEAR', values = 'TOTAL_SALES').fillna(0)\n",
    "\n",
    "# Plot the grouped bar chart\n",
    "sales_pivot.plot(kind = 'bar', figsize = (14, 8))\n",
    "\n",
    "# Formatting\n",
    "plt.title('Total Sales by Product (2020 vs 2021)')\n",
    "plt.xlabel('Product Name')\n",
    "plt.ylabel('Total Sales in $10M')\n",
    "plt.xticks(rotation = 45, ha = 'right')\n",
    "plt.legend(title = 'Year')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c97c806",
   "metadata": {},
   "source": [
    "### Create a bar graph showing the comparison between retailers for 2021 and 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553cd2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by RETAILER and YEAR, summing UNITS_SOLD\n",
    "sales_summary = rush_sales_with_total.groupby(['RETAILER', 'YEAR'])['UNITS_SOLD'].sum().reset_index()\n",
    "\n",
    "# Pivot so each YEAR is a separate column\n",
    "sales_pivot = sales_summary.pivot(index = 'RETAILER', columns = 'YEAR', values = 'UNITS_SOLD').fillna(0)\n",
    "\n",
    "# Plot the grouped bar chart\n",
    "ax = sales_pivot.plot(kind = 'bar', figsize = (10, 6))\n",
    "\n",
    "# Formatting\n",
    "plt.title('Units Sold by Retailer (2020 vs 2021)')\n",
    "plt.xlabel('Retailer')\n",
    "plt.ylabel('Units Sold')\n",
    "plt.xticks(rotation = 45, ha = 'right')\n",
    "plt.legend(title = 'Year')\n",
    "\n",
    "# Show full integer values on y-axis\n",
    "ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, _: f'{int(x):,}'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
